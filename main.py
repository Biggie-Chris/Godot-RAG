import os
from dotenv import load_dotenv
from openai import OpenAI

def load_environment():
    """åŠ è½½ç¯å¢ƒå˜é‡"""
    load_dotenv()
    
    api_key = os.getenv('OPENAI_API_KEY')
    base_url = os.getenv('OPENAI_BASE_URL')
    
    if not api_key:
        raise ValueError("OPENAI_API_KEY not found in .env file")
    if not base_url:
        raise ValueError("OPENAI_BASE_URL not found in .env file")
    
    print(f"âœ… æˆåŠŸåŠ è½½ç¯å¢ƒå˜é‡")
    print(f"   API Base URL: {base_url}")
    print(f"   API Key: {api_key[:10]}...{api_key[-4:]}")
    
    return api_key, base_url

def initialize_openai_client(api_key, base_url):
    """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
    client = OpenAI(
        api_key=api_key,
        base_url=base_url
    )
    print("âœ… OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    return client

def chat_with_ai(client, model="Qwen/Qwen3-32B"):
    """ä¸AIè¿›è¡Œå¯¹è¯"""
    print(f"\nğŸ¤– å¼€å§‹ä¸ {model} å¯¹è¯ (è¾“å…¥ 'quit' é€€å‡º)")
    print("-" * 50)
    
    conversation_history = []
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ ä½ : ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                print("ğŸ‘‹ å†è§ï¼")
                break
                
            if not user_input:
                print("âš ï¸  è¯·è¾“å…¥æœ‰æ•ˆå†…å®¹")
                continue
            
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯å†å²
            conversation_history.append({"role": "user", "content": user_input})
            
            print("ğŸ¤” AIæ­£åœ¨æ€è€ƒ...")
            
            # è°ƒç”¨API
            response = client.chat.completions.create(
                model=model,
                messages=conversation_history,
                max_tokens=500,
                temperature=0.7
            )
            
            # è·å–AIå›å¤
            ai_response = response.choices[0].message.content
            print(f"\nğŸ¤– AI: {ai_response}")
            
            # æ·»åŠ AIå›å¤åˆ°å¯¹è¯å†å²
            conversation_history.append({"role": "assistant", "content": ai_response})
            
            # æ˜¾ç¤ºtokenä½¿ç”¨æƒ…å†µ
            usage = response.usage
            print(f"ğŸ“Š Tokenä½¿ç”¨: è¾“å…¥{usage.prompt_tokens} / è¾“å‡º{usage.completion_tokens} / æ€»è®¡{usage.total_tokens}")
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œå†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
            print("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIé…ç½®")

def test_api_connection(client, model="Qwen/Qwen3-32B"):
    """æµ‹è¯•APIè¿æ¥"""
    print("ğŸ” æµ‹è¯•APIè¿æ¥...")
    
    try:
        # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•æ¶ˆæ¯
        test_messages = [{"role": "user", "content": "è¯·ç®€å•å›å¤'è¿æ¥æˆåŠŸ'"}]
        
        response = client.chat.completions.create(
            model=model,
            messages=test_messages,
            max_tokens=10
        )
        
        test_response = response.choices[0].message.content
        print(f"âœ… APIè¿æ¥æµ‹è¯•æˆåŠŸ: {test_response}")
        return True
        
    except Exception as e:
        print(f"âŒ APIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¤§æ¨¡å‹APIå¯¹è¯æµ‹è¯•ç¨‹åº")
    print("=" * 50)
    
    try:
        # 1. åŠ è½½ç¯å¢ƒå˜é‡
        api_key, base_url = load_environment()
        
        # 2. åˆå§‹åŒ–å®¢æˆ·ç«¯
        client = initialize_openai_client(api_key, base_url)
        
        # 3. æµ‹è¯•APIè¿æ¥
        if test_api_connection(client):
            # 4. å¼€å§‹å¯¹è¯
            chat_with_ai(client)
        else:
            print("âŒ APIè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
            
    except Exception as e:
        print(f"âŒ ç¨‹åºåˆå§‹åŒ–å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥.envæ–‡ä»¶é…ç½®æ˜¯å¦æ­£ç¡®")

if __name__ == "__main__":
    main()